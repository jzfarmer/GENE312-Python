{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# hw7pr3:  titanic-passenger clasification via nearest neighbors\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries!\n",
    "import numpy as np      # numpy is Python's \"array\" library\n",
    "import pandas as pd     # Pandas is Python's \"data\" library (\"dataframe\" == spreadsheet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "titanic4.csv : file read!\n"
     ]
    }
   ],
   "source": [
    "# let's read in our digits data...\n",
    "# \n",
    "# for read_csv, use header=0 when row 0 is a header row\n",
    "# \n",
    "filename = 'titanic4.csv'\n",
    "df = pd.read_csv(filename, header=0)   # read the file w/header row #0\n",
    "print(f\"{filename} : file read!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>survived</th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>ticket</th>\n",
       "      <th>fare</th>\n",
       "      <th>cabin</th>\n",
       "      <th>embarked</th>\n",
       "      <th>boat</th>\n",
       "      <th>body</th>\n",
       "      <th>home.dest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>Ali, Mr. Ahmed</td>\n",
       "      <td>male</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/O.Q. 3101311</td>\n",
       "      <td>7.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>Ali, Mr. William</td>\n",
       "      <td>male</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/O.Q. 3101312</td>\n",
       "      <td>7.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.0</td>\n",
       "      <td>Argentina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lower Clapton, Middlesex or Erdington, Birmingham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>Allum, Mr. Owen George</td>\n",
       "      <td>male</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2223</td>\n",
       "      <td>8.3000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>NaN</td>\n",
       "      <td>259.0</td>\n",
       "      <td>Windsor, England New York, NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>Andersen-Jensen, Miss. Carla Christine Nielsine</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>350046</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pclass  survived                                             name     sex  \\\n",
       "0       3        -1                                   Ali, Mr. Ahmed    male   \n",
       "1       3        -1                                 Ali, Mr. William    male   \n",
       "2       3        -1                         Allen, Mr. William Henry    male   \n",
       "3       3        -1                           Allum, Mr. Owen George    male   \n",
       "4       3        -1  Andersen-Jensen, Miss. Carla Christine Nielsine  female   \n",
       "\n",
       "    age  sibsp  parch              ticket    fare cabin embarked boat   body  \\\n",
       "0  24.0      0      0  SOTON/O.Q. 3101311  7.0500   NaN        S  NaN    NaN   \n",
       "1  25.0      0      0  SOTON/O.Q. 3101312  7.0500   NaN        S  NaN   79.0   \n",
       "2  35.0      0      0              373450  8.0500   NaN        S  NaN    NaN   \n",
       "3  18.0      0      0                2223  8.3000   NaN        S  NaN  259.0   \n",
       "4  19.0      1      0              350046  7.8542   NaN        S   16    NaN   \n",
       "\n",
       "                                           home.dest  \n",
       "0                                                NaN  \n",
       "1                                          Argentina  \n",
       "2  Lower Clapton, Middlesex or Erdington, Birmingham  \n",
       "3                      Windsor, England New York, NY  \n",
       "4                                                NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# before converting to a numpy array, let's use some pandas data-viewing and -cleaning...\n",
    "#\n",
    "\n",
    "df.head()   # this shows the first few rows, to get a sense of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 14 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   pclass     1309 non-null   int64  \n",
      " 1   survived   1309 non-null   int64  \n",
      " 2   name       1309 non-null   object \n",
      " 3   sex        1309 non-null   object \n",
      " 4   age        1046 non-null   float64\n",
      " 5   sibsp      1309 non-null   int64  \n",
      " 6   parch      1309 non-null   int64  \n",
      " 7   ticket     1309 non-null   object \n",
      " 8   fare       1308 non-null   float64\n",
      " 9   cabin      295 non-null    object \n",
      " 10  embarked   1307 non-null   object \n",
      " 11  boat       486 non-null    object \n",
      " 12  body       121 non-null    float64\n",
      " 13  home.dest  745 non-null    object \n",
      "dtypes: float64(3), int64(4), object(7)\n",
      "memory usage: 143.3+ KB\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# this df.info() call will show the different features (columns), their types, and how many non-null there are ...\n",
    "#\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 10 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   pclass    1309 non-null   int64  \n",
      " 1   survived  1309 non-null   int64  \n",
      " 2   name      1309 non-null   object \n",
      " 3   sex       1309 non-null   object \n",
      " 4   age       1046 non-null   float64\n",
      " 5   sibsp     1309 non-null   int64  \n",
      " 6   parch     1309 non-null   int64  \n",
      " 7   ticket    1309 non-null   object \n",
      " 8   fare      1308 non-null   float64\n",
      " 9   embarked  1307 non-null   object \n",
      "dtypes: float64(2), int64(4), object(4)\n",
      "memory usage: 102.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# ok!  let's drop the columns with too few items: cabin, boat, body, and home.dest\n",
    "df = df.drop('cabin', axis=1)  # axis = 1 indicates we want to drop a column, not a row\n",
    "df = df.drop('boat', axis=1)  \n",
    "df = df.drop('body', axis=1)  \n",
    "df = df.drop('home.dest', axis=1)  \n",
    "df.info()  # re-look at the data ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1309 entries, 0 to 1308\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   pclass    1309 non-null   int64  \n",
      " 1   survived  1309 non-null   int64  \n",
      " 2   sex       1309 non-null   object \n",
      " 3   age       1046 non-null   float64\n",
      " 4   sibsp     1309 non-null   int64  \n",
      " 5   parch     1309 non-null   int64  \n",
      "dtypes: float64(1), int64(4), object(1)\n",
      "memory usage: 61.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# next... let's drop the columns that will probably not help us  ticket, fare, embarked, name\n",
    "df = df.drop('ticket', axis=1)  \n",
    "df = df.drop('fare', axis=1)  \n",
    "df = df.drop('embarked', axis=1)  \n",
    "df = df.drop('name', axis=1)  \n",
    "df.info()  # re-look at the data ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1046 entries, 0 to 1308\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   pclass    1046 non-null   int64  \n",
      " 1   survived  1046 non-null   int64  \n",
      " 2   sex       1046 non-null   object \n",
      " 3   age       1046 non-null   float64\n",
      " 4   sibsp     1046 non-null   int64  \n",
      " 5   parch     1046 non-null   int64  \n",
      "dtypes: float64(1), int64(4), object(1)\n",
      "memory usage: 57.2+ KB\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# drop all of the missing data (the \"na\" elements)\n",
    "#\n",
    "df = df.dropna()\n",
    "df.info()   # re-look at the data...   (all are now 1043)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1046 entries, 0 to 1308\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   pclass    1046 non-null   int64  \n",
      " 1   survived  1046 non-null   int64  \n",
      " 2   sex       1046 non-null   int64  \n",
      " 3   age       1046 non-null   float64\n",
      " 4   sibsp     1046 non-null   int64  \n",
      " 5   parch     1046 non-null   int64  \n",
      "dtypes: float64(1), int64(5)\n",
      "memory usage: 57.2 KB\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# everything needs to be numeric, but the male/female (\"sex\") is a string... need to fix this!\n",
    "#\n",
    "\n",
    "def translate(s):\n",
    "    \"\"\" from string to numeric value\n",
    "    \"\"\"\n",
    "    d = { 'male':0, 'female':1 }\n",
    "    return d[s]\n",
    "\n",
    "df['sex'] = df['sex'].map(translate)     # this line converts from string to numeric value\n",
    "\n",
    "df.info()   # re-look at the data...   (make sure all are numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pclass', 'survived', 'sex', 'age', 'sibsp', 'parch']\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# let's AUTOMATICALLY get the columns names in a list!\n",
    "#\n",
    "column_name_list = df.columns.values.tolist()\n",
    "print(column_name_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.  -1.   0.  24.   0.   0. ]\n",
      " [ 3.  -1.   0.  25.   0.   0. ]\n",
      " [ 3.  -1.   0.  35.   0.   0. ]\n",
      " ...\n",
      " [ 3.   0.   0.  26.5  0.   0. ]\n",
      " [ 3.   0.   0.  27.   0.   0. ]\n",
      " [ 3.   0.   0.  29.   0.   0. ]]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# let's convert our data to a numpy array, named A\n",
    "#\n",
    "A = df.values\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+++ Start of data definitions +++\n",
      "\n",
      "X_all is [[ 3.   0.  24.   0.   0. ]\n",
      " [ 3.   0.  25.   0.   0. ]\n",
      " [ 3.   0.  35.   0.   0. ]\n",
      " ...\n",
      " [ 3.   0.  26.5  0.   0. ]\n",
      " [ 3.   0.  27.   0.   0. ]\n",
      " [ 3.   0.  29.   0.   0. ]] (1046, 5)\n",
      "y_all is [-1. -1. -1. ...  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print(\"+++ Start of data definitions +++\\n\")\n",
    "\n",
    "# if we need to drop a column in the middle, we have to \"restack\" the arrays together:\n",
    "X_all = np.hstack( (A[:,0:1], A[:,2:]) )  # X (features) ... is all rows, columns 0, not_1, 2, 3, 4, 5\n",
    "y_all = A[:,1]                            # y (labels) ... is all rows, column 1 only\n",
    "\n",
    "print(\"X_all is\", X_all, X_all.shape)\n",
    "print(\"y_all is\", y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test COLS:  COLS['age'] is 2\n",
      "\n",
      "Test COL_NAMES:   COL_NAMES[0] is pclass\n",
      "the_data_row is [ 1.  1.  1. 26.  0.  0.]\n",
      "\n",
      "Their age is  1.0\n",
      "\n",
      "Simpler to type:  26.0\n"
     ]
    }
   ],
   "source": [
    "# column order is captured in these two \"Python dictionaries\":\n",
    "\n",
    "NUM_TO_SPECIES = { 0:\"perished\", 1:\"survived\" }\n",
    "\n",
    "SPECIES_TO_NUM = { \"perished\":0, \"survived\":1 }\n",
    "\n",
    "COLS = {               # also: FEATURES\n",
    "    \"pclass\":0,\n",
    "    \"sex\":1,           # 'survived' has been removed: it's the y_all (labels)\n",
    "    \"age\":2,\n",
    "    \"sibsp\":3,         # should use this horizontal space more effectively!\n",
    "    \"parch\":4,\n",
    "}\n",
    "# test this\n",
    "print(\"Test COLS:  COLS['age'] is\", COLS['age'])\n",
    "\n",
    "# reverse the key/value ordering\n",
    "COL_NAMES = {}\n",
    "for key in COLS:\n",
    "    value = COLS[key]\n",
    "    COL_NAMES[value] = key # reversed!\n",
    "\n",
    "print()   # let's test the reversed dictionary...\n",
    "print(\"Test COL_NAMES:   COL_NAMES[0] is\", COL_NAMES[0])\n",
    "\n",
    "# let's use the dictionary!\n",
    "the_data_row = A[55]  # digit at index 901\n",
    "print(\"the_data_row is\", the_data_row)\n",
    "print()\n",
    "print(\"Their age is \", the_data_row[COLS['age']])\n",
    "print()\n",
    "print(\"Simpler to type: \", the_data_row[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# the remainder of the workflow is for you to build!\n",
    "#\n",
    "#   [1] copy-and-paste is your friend!   HOWEVER,\n",
    "#\n",
    "#   [2] here, our goal is to understand what each cell is doing (by trying it out!!)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
      " -1. -1. -1. -1. -1. -1.  1.  1.  0.]\n"
     ]
    }
   ],
   "source": [
    "print(y_all[:45])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 1. ... 0. 1. 0.]\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# break our dataset into distinct pieces:   unknown vs labeled\n",
    "#\n",
    "\n",
    "NUM_UNKNOWN = 42  # 42 unknown\n",
    "\n",
    "X_unknown = X_all[:NUM_UNKNOWN,:]  # unknown up to here...\n",
    "y_unknown = y_all[:NUM_UNKNOWN]    # unknown up to here...\n",
    "\n",
    "X_labeled_orig = X_all[NUM_UNKNOWN:,:]  # labeled data starts at this index\n",
    "y_labeled_orig = y_all[NUM_UNKNOWN:]    # labeled data starts at this index\n",
    "\n",
    "#\n",
    "# we scramble the data - but _only_ the labeled data!\n",
    "# \n",
    "indices = np.random.permutation(len(y_labeled_orig))  # indices is a permutation-list\n",
    "\n",
    "# we scramble both X and y, necessarily with the same permutation\n",
    "X_labeled = X_labeled_orig[indices]              # we must apply the _same_ permutation to each!\n",
    "y_labeled = y_labeled_orig[indices]              # again...\n",
    "print(y_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighting age by 1.0\n",
      "Weighting pclass by 10.0\n",
      "Weighting sex by 10.0\n",
      "Weighting sibsp by 1.0\n",
      "Weighting parch by 1.0\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# we can re-weight different features here...\n",
    "#\n",
    "\n",
    "COL_WEIGHT = {              # also: FEATURE_WEIGHT  compare:  COLS\n",
    "    'age':1.0,\n",
    "    'pclass':10.0,\n",
    "    'sex':10.0,\n",
    "    'sibsp':1.0,\n",
    "    'parch':1.0,\n",
    "}\n",
    "\n",
    "for col_name in COL_WEIGHT:\n",
    "    i = COLS[col_name]    # get the column index, i, of the col_name\n",
    "    weight = COL_WEIGHT[col_name]\n",
    "    print(\"Weighting\", col_name, \"by\", weight)   # weighting == \"multiplying\"\n",
    "    \n",
    "    X_labeled[:,i] *= weight      # multiply by the weight to give this column (\"feature\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# the rest of the cells are similar to all of the others...\n",
    "#\n",
    "\n",
    "# you'll want to grab those..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing with 200 rows; training with 804 rows\n"
     ]
    }
   ],
   "source": [
    "# +++ This is the \"Model-building and -training Cell\"\n",
    "#       \n",
    "# Create a kNN model and train it! \n",
    "#\n",
    "# We next separate into test data and training data ... \n",
    "#    + We will train on the training data...\n",
    "#    + We will _not_ train on the testing data.\n",
    "#\n",
    "# Then, afterward, we will test on the testing data -- and see how well we do!\n",
    "#\n",
    "\n",
    "#\n",
    "# most common convention:  train on 80%, test on 20%    Let's define the TEST_PERCENT\n",
    "#\n",
    "NUM_ROWS = X_labeled.shape[0]     # the number of labeled rows\n",
    "TEST_PERCENT = 0.20\n",
    "TEST_SIZE = int(TEST_PERCENT*NUM_ROWS)   # no harm in rounding down\n",
    "\n",
    "X_test = X_labeled[:TEST_SIZE]    # first section are for testing\n",
    "y_test = y_labeled[:TEST_SIZE]\n",
    "\n",
    "X_train = X_labeled[TEST_SIZE:]   # all the rest are for training\n",
    "y_train = y_labeled[TEST_SIZE:]\n",
    "\n",
    "print(\"testing with\", TEST_SIZE, \"rows; training with\", (NUM_ROWS-TEST_SIZE), \"rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0.,\n",
       "       0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0.,\n",
       "       0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1.,\n",
       "       0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1.,\n",
       "       1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 0.,\n",
       "       0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 1., 0., 0.,\n",
       "       1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0.,\n",
       "       0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0.,\n",
       "       0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test # parished or survived for each passenger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created and trained a knn classifier with k = 71\n"
     ]
    }
   ],
   "source": [
    "# +++ This is the \"Model-building and -training Cell\"\n",
    "#       \n",
    "# Create a kNN model and train it! \n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "k = 71   # we don't know what k to use, so we guess!  (71 will _not_ be a good value)\n",
    "knn_model = KNeighborsClassifier(n_neighbors=k)   # here, k is the \"k\" in kNN\n",
    "\n",
    "# we train the model (one line!)\n",
    "knn_model.fit(X_train, y_train)                              # yay!  trained!\n",
    "print(\"Created and trained a knn classifier with k =\", k)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: [0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1.\n",
      " 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1.\n",
      " 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0.\n",
      " 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 1. 1. 1. 0. 0. 0. 1.]\n",
      "Actual labels: [0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1.\n",
      " 1. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1.\n",
      " 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0.\n",
      " 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1.\n",
      " 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# +++ This is the \"Model-testing Cell\"\n",
    "#\n",
    "# Now, let's see how well we did on our \"held-out data\" (the testing data)\n",
    "predicted_labels = knn_model.predict(X_test)\n",
    "actual_labels = y_test\n",
    "\n",
    "# Let's print them so we can compare...\n",
    "print(\"Predicted labels:\", predicted_labels)\n",
    "print(\"Actual labels:\", actual_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 0    |  0.0  0.0  |   perished perished   \n",
      "row 1    |  1.0  1.0  |   survived survived   \n",
      "row 2    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 3    |  1.0  1.0  |   survived survived   \n",
      "row 4    |  0.0  0.0  |   perished perished   \n",
      "row 5    |  1.0  1.0  |   survived survived   \n",
      "row 6    |  0.0  0.0  |   perished perished   \n",
      "row 7    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 8    |  0.0  0.0  |   perished perished   \n",
      "row 9    |  0.0  0.0  |   perished perished   \n",
      "row 10    |  0.0  0.0  |   perished perished   \n",
      "row 11    |  1.0  1.0  |   survived survived   \n",
      "row 12    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 13    |  0.0  0.0  |   perished perished   \n",
      "row 14    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 15    |  1.0  1.0  |   survived survived   \n",
      "row 16    |  0.0  0.0  |   perished perished   \n",
      "row 17    |  1.0  0.0  |   survived perished   incorrect\n",
      "row 18    |  1.0  1.0  |   survived survived   \n",
      "row 19    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 20    |  1.0  1.0  |   survived survived   \n",
      "row 21    |  0.0  0.0  |   perished perished   \n",
      "row 22    |  1.0  1.0  |   survived survived   \n",
      "row 23    |  1.0  1.0  |   survived survived   \n",
      "row 24    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 25    |  0.0  0.0  |   perished perished   \n",
      "row 26    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 27    |  1.0  1.0  |   survived survived   \n",
      "row 28    |  1.0  1.0  |   survived survived   \n",
      "row 29    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 30    |  0.0  0.0  |   perished perished   \n",
      "row 31    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 32    |  0.0  0.0  |   perished perished   \n",
      "row 33    |  0.0  0.0  |   perished perished   \n",
      "row 34    |  0.0  0.0  |   perished perished   \n",
      "row 35    |  1.0  1.0  |   survived survived   \n",
      "row 36    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 37    |  0.0  0.0  |   perished perished   \n",
      "row 38    |  0.0  0.0  |   perished perished   \n",
      "row 39    |  0.0  0.0  |   perished perished   \n",
      "row 40    |  1.0  1.0  |   survived survived   \n",
      "row 41    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 42    |  1.0  1.0  |   survived survived   \n",
      "row 43    |  1.0  1.0  |   survived survived   \n",
      "row 44    |  1.0  0.0  |   survived perished   incorrect\n",
      "row 45    |  1.0  1.0  |   survived survived   \n",
      "row 46    |  0.0  0.0  |   perished perished   \n",
      "row 47    |  1.0  1.0  |   survived survived   \n",
      "row 48    |  0.0  0.0  |   perished perished   \n",
      "row 49    |  1.0  1.0  |   survived survived   \n",
      "row 50    |  1.0  1.0  |   survived survived   \n",
      "row 51    |  0.0  0.0  |   perished perished   \n",
      "row 52    |  1.0  1.0  |   survived survived   \n",
      "row 53    |  0.0  0.0  |   perished perished   \n",
      "row 54    |  1.0  1.0  |   survived survived   \n",
      "row 55    |  0.0  0.0  |   perished perished   \n",
      "row 56    |  0.0  0.0  |   perished perished   \n",
      "row 57    |  1.0  1.0  |   survived survived   \n",
      "row 58    |  0.0  0.0  |   perished perished   \n",
      "row 59    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 60    |  0.0  0.0  |   perished perished   \n",
      "row 61    |  0.0  0.0  |   perished perished   \n",
      "row 62    |  1.0  1.0  |   survived survived   \n",
      "row 63    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 64    |  1.0  1.0  |   survived survived   \n",
      "row 65    |  0.0  0.0  |   perished perished   \n",
      "row 66    |  0.0  0.0  |   perished perished   \n",
      "row 67    |  0.0  0.0  |   perished perished   \n",
      "row 68    |  0.0  0.0  |   perished perished   \n",
      "row 69    |  0.0  0.0  |   perished perished   \n",
      "row 70    |  1.0  1.0  |   survived survived   \n",
      "row 71    |  0.0  0.0  |   perished perished   \n",
      "row 72    |  0.0  0.0  |   perished perished   \n",
      "row 73    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 74    |  0.0  0.0  |   perished perished   \n",
      "row 75    |  0.0  0.0  |   perished perished   \n",
      "row 76    |  0.0  0.0  |   perished perished   \n",
      "row 77    |  1.0  1.0  |   survived survived   \n",
      "row 78    |  0.0  0.0  |   perished perished   \n",
      "row 79    |  0.0  0.0  |   perished perished   \n",
      "row 80    |  1.0  0.0  |   survived perished   incorrect\n",
      "row 81    |  0.0  0.0  |   perished perished   \n",
      "row 82    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 83    |  0.0  0.0  |   perished perished   \n",
      "row 84    |  0.0  0.0  |   perished perished   \n",
      "row 85    |  0.0  0.0  |   perished perished   \n",
      "row 86    |  0.0  0.0  |   perished perished   \n",
      "row 87    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 88    |  0.0  0.0  |   perished perished   \n",
      "row 89    |  0.0  0.0  |   perished perished   \n",
      "row 90    |  0.0  0.0  |   perished perished   \n",
      "row 91    |  0.0  0.0  |   perished perished   \n",
      "row 92    |  0.0  0.0  |   perished perished   \n",
      "row 93    |  0.0  0.0  |   perished perished   \n",
      "row 94    |  0.0  0.0  |   perished perished   \n",
      "row 95    |  0.0  0.0  |   perished perished   \n",
      "row 96    |  0.0  0.0  |   perished perished   \n",
      "row 97    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 98    |  0.0  0.0  |   perished perished   \n",
      "row 99    |  1.0  1.0  |   survived survived   \n",
      "row 100    |  0.0  0.0  |   perished perished   \n",
      "row 101    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 102    |  1.0  1.0  |   survived survived   \n",
      "row 103    |  0.0  0.0  |   perished perished   \n",
      "row 104    |  1.0  1.0  |   survived survived   \n",
      "row 105    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 106    |  1.0  0.0  |   survived perished   incorrect\n",
      "row 107    |  0.0  0.0  |   perished perished   \n",
      "row 108    |  0.0  0.0  |   perished perished   \n",
      "row 109    |  1.0  0.0  |   survived perished   incorrect\n",
      "row 110    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 111    |  1.0  1.0  |   survived survived   \n",
      "row 112    |  0.0  0.0  |   perished perished   \n",
      "row 113    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 114    |  0.0  0.0  |   perished perished   \n",
      "row 115    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 116    |  1.0  1.0  |   survived survived   \n",
      "row 117    |  1.0  0.0  |   survived perished   incorrect\n",
      "row 118    |  0.0  0.0  |   perished perished   \n",
      "row 119    |  0.0  0.0  |   perished perished   \n",
      "row 120    |  0.0  0.0  |   perished perished   \n",
      "row 121    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 122    |  0.0  0.0  |   perished perished   \n",
      "row 123    |  1.0  1.0  |   survived survived   \n",
      "row 124    |  1.0  1.0  |   survived survived   \n",
      "row 125    |  1.0  1.0  |   survived survived   \n",
      "row 126    |  0.0  0.0  |   perished perished   \n",
      "row 127    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 128    |  0.0  0.0  |   perished perished   \n",
      "row 129    |  0.0  0.0  |   perished perished   \n",
      "row 130    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 131    |  0.0  0.0  |   perished perished   \n",
      "row 132    |  0.0  0.0  |   perished perished   \n",
      "row 133    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 134    |  0.0  0.0  |   perished perished   \n",
      "row 135    |  1.0  0.0  |   survived perished   incorrect\n",
      "row 136    |  1.0  1.0  |   survived survived   \n",
      "row 137    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 138    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 139    |  1.0  1.0  |   survived survived   \n",
      "row 140    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 141    |  0.0  0.0  |   perished perished   \n",
      "row 142    |  1.0  0.0  |   survived perished   incorrect\n",
      "row 143    |  1.0  1.0  |   survived survived   \n",
      "row 144    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 145    |  0.0  0.0  |   perished perished   \n",
      "row 146    |  0.0  0.0  |   perished perished   \n",
      "row 147    |  0.0  0.0  |   perished perished   \n",
      "row 148    |  1.0  1.0  |   survived survived   \n",
      "row 149    |  0.0  0.0  |   perished perished   \n",
      "row 150    |  0.0  0.0  |   perished perished   \n",
      "row 151    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 152    |  0.0  0.0  |   perished perished   \n",
      "row 153    |  0.0  0.0  |   perished perished   \n",
      "row 154    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 155    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 156    |  1.0  1.0  |   survived survived   \n",
      "row 157    |  0.0  0.0  |   perished perished   \n",
      "row 158    |  0.0  0.0  |   perished perished   \n",
      "row 159    |  0.0  0.0  |   perished perished   \n",
      "row 160    |  0.0  0.0  |   perished perished   \n",
      "row 161    |  0.0  0.0  |   perished perished   \n",
      "row 162    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 163    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 164    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 165    |  1.0  1.0  |   survived survived   \n",
      "row 166    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 167    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 168    |  0.0  0.0  |   perished perished   \n",
      "row 169    |  0.0  0.0  |   perished perished   \n",
      "row 170    |  0.0  0.0  |   perished perished   \n",
      "row 171    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 172    |  0.0  0.0  |   perished perished   \n",
      "row 173    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 174    |  1.0  1.0  |   survived survived   \n",
      "row 175    |  1.0  1.0  |   survived survived   \n",
      "row 176    |  0.0  0.0  |   perished perished   \n",
      "row 177    |  0.0  0.0  |   perished perished   \n",
      "row 178    |  0.0  0.0  |   perished perished   \n",
      "row 179    |  0.0  0.0  |   perished perished   \n",
      "row 180    |  1.0  0.0  |   survived perished   incorrect\n",
      "row 181    |  0.0  0.0  |   perished perished   \n",
      "row 182    |  1.0  1.0  |   survived survived   \n",
      "row 183    |  0.0  0.0  |   perished perished   \n",
      "row 184    |  0.0  0.0  |   perished perished   \n",
      "row 185    |  0.0  0.0  |   perished perished   \n",
      "row 186    |  0.0  0.0  |   perished perished   \n",
      "row 187    |  0.0  0.0  |   perished perished   \n",
      "row 188    |  0.0  0.0  |   perished perished   \n",
      "row 189    |  0.0  0.0  |   perished perished   \n",
      "row 190    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 191    |  1.0  1.0  |   survived survived   \n",
      "row 192    |  0.0  0.0  |   perished perished   \n",
      "row 193    |  1.0  0.0  |   survived perished   incorrect\n",
      "row 194    |  1.0  1.0  |   survived survived   \n",
      "row 195    |  1.0  1.0  |   survived survived   \n",
      "row 196    |  0.0  0.0  |   perished perished   \n",
      "row 197    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 198    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 199    |  1.0  1.0  |   survived survived   \n",
      "\n",
      "Correct: 147 out of 200\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Let's print these more helpfully, in a vertical table\n",
    "#\n",
    "#\n",
    "# Let's print these more helpfully, in a vertical table\n",
    "#\n",
    "\n",
    "def compare_labels(predicted_labels, actual_labels):\n",
    "    \"\"\" a nicer comparison, including counting how many are correct \"\"\"\n",
    "    NUM_LABELS = predicted_labels.shape[0]\n",
    "    num_correct = 0\n",
    "    \n",
    "    for i in range(NUM_LABELS):\n",
    "        p = predicted_labels[i]\n",
    "        a = actual_labels[i]\n",
    "        p_label = NUM_TO_SPECIES[p]\n",
    "        a_label = NUM_TO_SPECIES[a]\n",
    "        if p == a:\n",
    "            toshow = \"\"\n",
    "            num_correct += 1\n",
    "        else:\n",
    "            toshow = \"incorrect\"\n",
    "            \n",
    "        print(f\"row {i}    |  {p}  {a}  |   {p_label} {a_label}   {toshow}\")   # cool! \"f-string\" printing\n",
    "        \n",
    "        # even spiffier \"formatted printing\"  (cool stuff!)  \n",
    "        #print(f\"row {i:2d}    |  {p:1.0f}  {a:1.0f}  |   {p_label:>15s} {a_label:<15s}   {toshow:<15s}\")\n",
    "        \n",
    "    # the loop is now complete...\n",
    "    print()\n",
    "    print(\"Correct:\", num_correct, \"out of\", NUM_LABELS)\n",
    "        \n",
    "        \n",
    "compare_labels(predicted_labels,actual_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k:  1 produces an average CV accuracy of  0.7487344720496895\n",
      "k:  2 produces an average CV accuracy of  0.7898214285714287\n",
      "k:  3 produces an average CV accuracy of  0.7947748447204969\n",
      "k:  4 produces an average CV accuracy of  0.8121894409937888\n",
      "k:  5 produces an average CV accuracy of  0.8084782608695653\n",
      "k:  6 produces an average CV accuracy of  0.8010093167701863\n",
      "k:  7 produces an average CV accuracy of  0.7960403726708074\n",
      "k:  8 produces an average CV accuracy of  0.7935403726708075\n",
      "k:  9 produces an average CV accuracy of  0.7985248447204969\n",
      "k: 10 produces an average CV accuracy of  0.8022670807453416\n",
      "k: 11 produces an average CV accuracy of  0.7960403726708074\n",
      "k: 12 produces an average CV accuracy of  0.8034782608695652\n",
      "k: 13 produces an average CV accuracy of  0.8022515527950311\n",
      "k: 14 produces an average CV accuracy of  0.8035093167701863\n",
      "k: 15 produces an average CV accuracy of  0.8084860248447205\n",
      "k: 16 produces an average CV accuracy of  0.8022515527950311\n",
      "k: 17 produces an average CV accuracy of  0.8059860248447205\n",
      "k: 18 produces an average CV accuracy of  0.8059782608695653\n",
      "k: 19 produces an average CV accuracy of  0.8010093167701863\n",
      "k: 20 produces an average CV accuracy of  0.7972826086956523\n",
      "k: 21 produces an average CV accuracy of  0.7960326086956522\n",
      "k: 22 produces an average CV accuracy of  0.793555900621118\n",
      "k: 23 produces an average CV accuracy of  0.7972826086956523\n",
      "k: 24 produces an average CV accuracy of  0.793555900621118\n",
      "k: 25 produces an average CV accuracy of  0.7947903726708075\n",
      "k: 26 produces an average CV accuracy of  0.7947981366459628\n",
      "k: 27 produces an average CV accuracy of  0.796024844720497\n",
      "k: 28 produces an average CV accuracy of  0.7947826086956521\n",
      "k: 29 produces an average CV accuracy of  0.7947748447204969\n",
      "k: 30 produces an average CV accuracy of  0.7898059006211179\n",
      "k: 31 produces an average CV accuracy of  0.7860636645962733\n",
      "k: 32 produces an average CV accuracy of  0.7885636645962733\n",
      "k: 33 produces an average CV accuracy of  0.7922981366459627\n",
      "k: 34 produces an average CV accuracy of  0.7885791925465837\n",
      "k: 35 produces an average CV accuracy of  0.7910636645962733\n",
      "k: 36 produces an average CV accuracy of  0.7873214285714287\n",
      "k: 37 produces an average CV accuracy of  0.7873136645962734\n",
      "k: 38 produces an average CV accuracy of  0.7885403726708075\n",
      "k: 39 produces an average CV accuracy of  0.7935170807453416\n",
      "k: 40 produces an average CV accuracy of  0.7922748447204968\n",
      "k: 41 produces an average CV accuracy of  0.7922826086956521\n",
      "k: 42 produces an average CV accuracy of  0.7897903726708074\n",
      "k: 43 produces an average CV accuracy of  0.7947748447204969\n",
      "k: 44 produces an average CV accuracy of  0.7947748447204969\n",
      "k: 45 produces an average CV accuracy of  0.7972593167701862\n",
      "k: 46 produces an average CV accuracy of  0.7910481366459627\n",
      "k: 47 produces an average CV accuracy of  0.7910481366459627\n",
      "k: 48 produces an average CV accuracy of  0.7873214285714285\n",
      "k: 49 produces an average CV accuracy of  0.7910481366459627\n",
      "k: 50 produces an average CV accuracy of  0.791055900621118\n",
      "k: 51 produces an average CV accuracy of  0.7898059006211181\n",
      "k: 52 produces an average CV accuracy of  0.7922981366459627\n",
      "k: 53 produces an average CV accuracy of  0.7898059006211181\n",
      "k: 54 produces an average CV accuracy of  0.7947826086956521\n",
      "k: 55 produces an average CV accuracy of  0.7922981366459627\n",
      "k: 56 produces an average CV accuracy of  0.7910481366459627\n",
      "k: 57 produces an average CV accuracy of  0.7922903726708075\n",
      "k: 58 produces an average CV accuracy of  0.7947826086956521\n",
      "k: 59 produces an average CV accuracy of  0.7935481366459627\n",
      "k: 60 produces an average CV accuracy of  0.7985093167701864\n",
      "k: 61 produces an average CV accuracy of  0.7947903726708074\n",
      "k: 62 produces an average CV accuracy of  0.7985093167701864\n",
      "k: 63 produces an average CV accuracy of  0.7972670807453417\n",
      "k: 64 produces an average CV accuracy of  0.7960248447204968\n",
      "k: 65 produces an average CV accuracy of  0.7985170807453417\n",
      "k: 66 produces an average CV accuracy of  0.7972748447204968\n",
      "k: 67 produces an average CV accuracy of  0.7985170807453416\n",
      "k: 68 produces an average CV accuracy of  0.7972670807453417\n",
      "k: 69 produces an average CV accuracy of  0.7997515527950311\n",
      "k: 70 produces an average CV accuracy of  0.7972670807453417\n",
      "k: 71 produces an average CV accuracy of  0.7985093167701864\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# ok!  We _could_ be finished -- except that we _guessed_ at the keighborhood size (we guessed a k of 71)\n",
    "#      Perhaps we should _explore_ whether other neighborhood sizes might better reflect our data... (?)\n",
    "\n",
    "#\n",
    "# to do this, we use \"cross validation\":  we split the _TRAINING_ data up and try different values of k\n",
    "#\n",
    "#\n",
    "# ok!  We _could_ be finished -- except that we _guessed_ at the keighborhood size (we guessed a k of 71)\n",
    "#      Perhaps we should _explore_ whether other neighborhood sizes might better reflect our data... (?)\n",
    "\n",
    "#\n",
    "# to do this, we use \"cross validation\":  we split the _TRAINING_ data up and try different values of k\n",
    "#\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#\n",
    "# cross-validation splits the training set into two pieces:\n",
    "#   + model-building and model-validation. We'll use \"build\" and \"validate\"\n",
    "#\n",
    "# Lab challenge:  [1] loop over all values of k (or all _odd_ values of k...)  \n",
    "#                 [2] assign best_k to the best one (highest average CV accuracy)\n",
    "\n",
    "for k in range(1,72):\n",
    "    knn_cv_model = KNeighborsClassifier(n_neighbors=k)   # build knn_model with current value of k\n",
    "\n",
    "    cv_scores = cross_val_score( knn_cv_model, X_train, y_train, cv=5 )  # 5 is the \"# of splits\" (5 -> 80/20)\n",
    "    #print('The 5 cross-validation accuracies: ', cv_scores,\"\\n\")\n",
    "    av = cv_scores.mean()\n",
    "    print(f'k: {k:2d} produces an average CV accuracy of ', av)\n",
    "\n",
    "# assign best value of k to best_k\n",
    "best_k = 4      # at the moment, by hand - should be programmatic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 4   yields the highest average CV accuracy.\n"
     ]
    }
   ],
   "source": [
    "# print(f\"k = {best_k}   yields the highest average CV accuracy.\")  # print the best one\n",
    "print(f\"k = {best_k}   yields the highest average CV accuracy.\")  # print the best one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created and trained a knn classifier with k = 4\n"
     ]
    }
   ],
   "source": [
    "# Now, we re-create and re-run the  \"Model-building and -training Cell\"\n",
    "#\n",
    "# Now, using best_k instead of the original, randomly-guessed value    How does it do?!\n",
    "# Now, we re-create and re-run the  \"Model-building and -training Cell\"\n",
    "#\n",
    "# Now, using best_k instead of the original, randomly-guessed value    How does it do?!\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_model = KNeighborsClassifier(n_neighbors=best_k)   # here, we use the best_k\n",
    "\n",
    "# we train the model (one line!)\n",
    "knn_model.fit(X_train, y_train)                              # yay!  trained!\n",
    "print(\"Created and trained a knn classifier with k =\", best_k) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: [0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1. 1.\n",
      " 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1.\n",
      " 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0.\n",
      " 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 1. 1. 1. 0. 0. 1. 1.]\n",
      "Actual labels: [0. 1. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 0. 1. 1. 1. 0. 1. 1.\n",
      " 1. 0. 1. 1. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 1.\n",
      " 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 1. 0. 0. 0.\n",
      " 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 1.\n",
      " 1. 0. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 0. 0. 1. 1. 0. 1. 1. 1.]\n",
      "row 0    |  0.0  0.0  |   perished perished   \n",
      "row 1    |  1.0  1.0  |   survived survived   \n",
      "row 2    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 3    |  1.0  1.0  |   survived survived   \n",
      "row 4    |  0.0  0.0  |   perished perished   \n",
      "row 5    |  1.0  1.0  |   survived survived   \n",
      "row 6    |  0.0  0.0  |   perished perished   \n",
      "row 7    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 8    |  0.0  0.0  |   perished perished   \n",
      "row 9    |  0.0  0.0  |   perished perished   \n",
      "row 10    |  0.0  0.0  |   perished perished   \n",
      "row 11    |  1.0  1.0  |   survived survived   \n",
      "row 12    |  1.0  1.0  |   survived survived   \n",
      "row 13    |  0.0  0.0  |   perished perished   \n",
      "row 14    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 15    |  1.0  1.0  |   survived survived   \n",
      "row 16    |  1.0  0.0  |   survived perished   incorrect\n",
      "row 17    |  1.0  0.0  |   survived perished   incorrect\n",
      "row 18    |  1.0  1.0  |   survived survived   \n",
      "row 19    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 20    |  1.0  1.0  |   survived survived   \n",
      "row 21    |  0.0  0.0  |   perished perished   \n",
      "row 22    |  1.0  1.0  |   survived survived   \n",
      "row 23    |  1.0  1.0  |   survived survived   \n",
      "row 24    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 25    |  0.0  0.0  |   perished perished   \n",
      "row 26    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 27    |  1.0  1.0  |   survived survived   \n",
      "row 28    |  1.0  1.0  |   survived survived   \n",
      "row 29    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 30    |  0.0  0.0  |   perished perished   \n",
      "row 31    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 32    |  0.0  0.0  |   perished perished   \n",
      "row 33    |  0.0  0.0  |   perished perished   \n",
      "row 34    |  0.0  0.0  |   perished perished   \n",
      "row 35    |  1.0  1.0  |   survived survived   \n",
      "row 36    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 37    |  0.0  0.0  |   perished perished   \n",
      "row 38    |  0.0  0.0  |   perished perished   \n",
      "row 39    |  0.0  0.0  |   perished perished   \n",
      "row 40    |  1.0  1.0  |   survived survived   \n",
      "row 41    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 42    |  1.0  1.0  |   survived survived   \n",
      "row 43    |  1.0  1.0  |   survived survived   \n",
      "row 44    |  1.0  0.0  |   survived perished   incorrect\n",
      "row 45    |  1.0  1.0  |   survived survived   \n",
      "row 46    |  0.0  0.0  |   perished perished   \n",
      "row 47    |  1.0  1.0  |   survived survived   \n",
      "row 48    |  0.0  0.0  |   perished perished   \n",
      "row 49    |  1.0  1.0  |   survived survived   \n",
      "row 50    |  1.0  1.0  |   survived survived   \n",
      "row 51    |  0.0  0.0  |   perished perished   \n",
      "row 52    |  1.0  1.0  |   survived survived   \n",
      "row 53    |  0.0  0.0  |   perished perished   \n",
      "row 54    |  1.0  1.0  |   survived survived   \n",
      "row 55    |  0.0  0.0  |   perished perished   \n",
      "row 56    |  0.0  0.0  |   perished perished   \n",
      "row 57    |  1.0  1.0  |   survived survived   \n",
      "row 58    |  0.0  0.0  |   perished perished   \n",
      "row 59    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 60    |  0.0  0.0  |   perished perished   \n",
      "row 61    |  0.0  0.0  |   perished perished   \n",
      "row 62    |  1.0  1.0  |   survived survived   \n",
      "row 63    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 64    |  1.0  1.0  |   survived survived   \n",
      "row 65    |  0.0  0.0  |   perished perished   \n",
      "row 66    |  0.0  0.0  |   perished perished   \n",
      "row 67    |  0.0  0.0  |   perished perished   \n",
      "row 68    |  0.0  0.0  |   perished perished   \n",
      "row 69    |  0.0  0.0  |   perished perished   \n",
      "row 70    |  1.0  1.0  |   survived survived   \n",
      "row 71    |  0.0  0.0  |   perished perished   \n",
      "row 72    |  0.0  0.0  |   perished perished   \n",
      "row 73    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 74    |  1.0  0.0  |   survived perished   incorrect\n",
      "row 75    |  0.0  0.0  |   perished perished   \n",
      "row 76    |  0.0  0.0  |   perished perished   \n",
      "row 77    |  1.0  1.0  |   survived survived   \n",
      "row 78    |  0.0  0.0  |   perished perished   \n",
      "row 79    |  0.0  0.0  |   perished perished   \n",
      "row 80    |  1.0  0.0  |   survived perished   incorrect\n",
      "row 81    |  1.0  0.0  |   survived perished   incorrect\n",
      "row 82    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 83    |  0.0  0.0  |   perished perished   \n",
      "row 84    |  1.0  0.0  |   survived perished   incorrect\n",
      "row 85    |  0.0  0.0  |   perished perished   \n",
      "row 86    |  0.0  0.0  |   perished perished   \n",
      "row 87    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 88    |  0.0  0.0  |   perished perished   \n",
      "row 89    |  0.0  0.0  |   perished perished   \n",
      "row 90    |  0.0  0.0  |   perished perished   \n",
      "row 91    |  0.0  0.0  |   perished perished   \n",
      "row 92    |  0.0  0.0  |   perished perished   \n",
      "row 93    |  0.0  0.0  |   perished perished   \n",
      "row 94    |  0.0  0.0  |   perished perished   \n",
      "row 95    |  0.0  0.0  |   perished perished   \n",
      "row 96    |  0.0  0.0  |   perished perished   \n",
      "row 97    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 98    |  0.0  0.0  |   perished perished   \n",
      "row 99    |  1.0  1.0  |   survived survived   \n",
      "row 100    |  0.0  0.0  |   perished perished   \n",
      "row 101    |  1.0  1.0  |   survived survived   \n",
      "row 102    |  1.0  1.0  |   survived survived   \n",
      "row 103    |  0.0  0.0  |   perished perished   \n",
      "row 104    |  1.0  1.0  |   survived survived   \n",
      "row 105    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 106    |  1.0  0.0  |   survived perished   incorrect\n",
      "row 107    |  0.0  0.0  |   perished perished   \n",
      "row 108    |  0.0  0.0  |   perished perished   \n",
      "row 109    |  1.0  0.0  |   survived perished   incorrect\n",
      "row 110    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 111    |  1.0  1.0  |   survived survived   \n",
      "row 112    |  0.0  0.0  |   perished perished   \n",
      "row 113    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 114    |  0.0  0.0  |   perished perished   \n",
      "row 115    |  1.0  1.0  |   survived survived   \n",
      "row 116    |  1.0  1.0  |   survived survived   \n",
      "row 117    |  1.0  0.0  |   survived perished   incorrect\n",
      "row 118    |  0.0  0.0  |   perished perished   \n",
      "row 119    |  0.0  0.0  |   perished perished   \n",
      "row 120    |  0.0  0.0  |   perished perished   \n",
      "row 121    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 122    |  0.0  0.0  |   perished perished   \n",
      "row 123    |  1.0  1.0  |   survived survived   \n",
      "row 124    |  1.0  1.0  |   survived survived   \n",
      "row 125    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 126    |  0.0  0.0  |   perished perished   \n",
      "row 127    |  1.0  1.0  |   survived survived   \n",
      "row 128    |  0.0  0.0  |   perished perished   \n",
      "row 129    |  0.0  0.0  |   perished perished   \n",
      "row 130    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 131    |  0.0  0.0  |   perished perished   \n",
      "row 132    |  0.0  0.0  |   perished perished   \n",
      "row 133    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 134    |  0.0  0.0  |   perished perished   \n",
      "row 135    |  0.0  0.0  |   perished perished   \n",
      "row 136    |  1.0  1.0  |   survived survived   \n",
      "row 137    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 138    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 139    |  1.0  1.0  |   survived survived   \n",
      "row 140    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 141    |  0.0  0.0  |   perished perished   \n",
      "row 142    |  0.0  0.0  |   perished perished   \n",
      "row 143    |  1.0  1.0  |   survived survived   \n",
      "row 144    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 145    |  0.0  0.0  |   perished perished   \n",
      "row 146    |  0.0  0.0  |   perished perished   \n",
      "row 147    |  0.0  0.0  |   perished perished   \n",
      "row 148    |  1.0  1.0  |   survived survived   \n",
      "row 149    |  0.0  0.0  |   perished perished   \n",
      "row 150    |  0.0  0.0  |   perished perished   \n",
      "row 151    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 152    |  0.0  0.0  |   perished perished   \n",
      "row 153    |  0.0  0.0  |   perished perished   \n",
      "row 154    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 155    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 156    |  1.0  1.0  |   survived survived   \n",
      "row 157    |  0.0  0.0  |   perished perished   \n",
      "row 158    |  0.0  0.0  |   perished perished   \n",
      "row 159    |  0.0  0.0  |   perished perished   \n",
      "row 160    |  0.0  0.0  |   perished perished   \n",
      "row 161    |  0.0  0.0  |   perished perished   \n",
      "row 162    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 163    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 164    |  1.0  1.0  |   survived survived   \n",
      "row 165    |  1.0  1.0  |   survived survived   \n",
      "row 166    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 167    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 168    |  0.0  0.0  |   perished perished   \n",
      "row 169    |  0.0  0.0  |   perished perished   \n",
      "row 170    |  0.0  0.0  |   perished perished   \n",
      "row 171    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 172    |  0.0  0.0  |   perished perished   \n",
      "row 173    |  1.0  1.0  |   survived survived   \n",
      "row 174    |  1.0  1.0  |   survived survived   \n",
      "row 175    |  1.0  1.0  |   survived survived   \n",
      "row 176    |  0.0  0.0  |   perished perished   \n",
      "row 177    |  0.0  0.0  |   perished perished   \n",
      "row 178    |  0.0  0.0  |   perished perished   \n",
      "row 179    |  0.0  0.0  |   perished perished   \n",
      "row 180    |  0.0  0.0  |   perished perished   \n",
      "row 181    |  0.0  0.0  |   perished perished   \n",
      "row 182    |  1.0  1.0  |   survived survived   \n",
      "row 183    |  0.0  0.0  |   perished perished   \n",
      "row 184    |  0.0  0.0  |   perished perished   \n",
      "row 185    |  0.0  0.0  |   perished perished   \n",
      "row 186    |  0.0  0.0  |   perished perished   \n",
      "row 187    |  0.0  0.0  |   perished perished   \n",
      "row 188    |  0.0  0.0  |   perished perished   \n",
      "row 189    |  0.0  0.0  |   perished perished   \n",
      "row 190    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 191    |  1.0  1.0  |   survived survived   \n",
      "row 192    |  0.0  0.0  |   perished perished   \n",
      "row 193    |  1.0  0.0  |   survived perished   incorrect\n",
      "row 194    |  1.0  1.0  |   survived survived   \n",
      "row 195    |  1.0  1.0  |   survived survived   \n",
      "row 196    |  0.0  0.0  |   perished perished   \n",
      "row 197    |  0.0  1.0  |   perished survived   incorrect\n",
      "row 198    |  1.0  1.0  |   survived survived   \n",
      "row 199    |  1.0  1.0  |   survived survived   \n",
      "\n",
      "Correct: 152 out of 200\n"
     ]
    }
   ],
   "source": [
    "# And, we re-create and re-run the  \"Model-testing Cell\"\n",
    "#\n",
    "# Now, using best_k instead of the original, randomly-guessed value    How does it do?!\n",
    "\n",
    "# And, we re-create and re-run the  \"Model-testing Cell\"\n",
    "#\n",
    "# Now, using best_k instead of the original, randomly-guessed value    How does it do?!\n",
    "\n",
    "# Now, run our test set!\n",
    "predicted_labels = knn_model.predict(X_test)\n",
    "actual_labels = y_test\n",
    "\n",
    "# Let's print them so we can compare...\n",
    "print(\"Predicted labels:\", predicted_labels)\n",
    "print(\"Actual labels:\", actual_labels)\n",
    "\n",
    "# and, we'll print our nicer table...\n",
    "compare_labels(predicted_labels,actual_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Plus, if new data arrives, you have a model with which to make predictions!\n",
    "#\n",
    "# here is a function for running new data (new flowers):\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_new_data defined.\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# test it out - with our own, typed data...\n",
    "#\n",
    "\n",
    "def predict_new_data(flower_data, knn_model):\n",
    "    \"\"\" allows the user to enter values, from file or by hand, and then predict \n",
    "        the label using the knn_model passed in as input\n",
    "    \"\"\"\n",
    "    # convert flower_data to a numpy array of float64 type (in case it's not already)\n",
    "    flower_data = np.asarray(flower_data)\n",
    "    flower_data.astype('float64')\n",
    "    # how many dimensions?\n",
    "    shape = flower_data.shape\n",
    "    if len(shape) == 1:  # only one flower in one dimension ([a,b,c,d]) We need [[a,b,c,d]]\n",
    "        flower_data = np.asarray( [flower_data] )  # need to wrap in extra square brackets!\n",
    "        \n",
    "    # print(flower_data.shape)\n",
    "    NUM_ROWS, NUM_COLS = flower_data.shape   # get number of rows and number of cols\n",
    "\n",
    "    # make the predictions\n",
    "    predictions = knn_model.predict(flower_data)\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # print results\n",
    "    for i in range(NUM_ROWS):\n",
    "        flower = flower_data[i]\n",
    "        predicted_label_as_number = predictions[i]\n",
    "        predicted_label = NUM_TO_SPECIES[predicted_label_as_number]  # convert (back) to string!\n",
    "        print(f\"For {flower} the model predicts...   {predicted_label}\")\n",
    "        \n",
    "    return predictions  # in case they're needed\n",
    "\n",
    "print(\"predict_new_data defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For [ 3.  0. 24.  0.  0.] the model predicts...   perished\n",
      "For [ 3.  0. 25.  0.  0.] the model predicts...   survived\n",
      "For [ 3.  0. 35.  0.  0.] the model predicts...   survived\n",
      "For [ 3.  0. 18.  0.  0.] the model predicts...   perished\n",
      "For [ 3.  1. 19.  1.  0.] the model predicts...   perished\n",
      "For [ 3.  0. 32.  0.  0.] the model predicts...   perished\n",
      "For [ 1.  0. 24.  0.  1.] the model predicts...   perished\n",
      "For [ 1.  1. 50.  0.  1.] the model predicts...   perished\n",
      "For [2. 0. 1. 2. 1.] the model predicts...   survived\n",
      "For [2. 1. 4. 2. 1.] the model predicts...   survived\n",
      "For [ 2.  1. 12.  2.  1.] the model predicts...   survived\n",
      "For [ 2.  1. 36.  0.  3.] the model predicts...   perished\n",
      "For [ 2.  0. 34.  0.  0.] the model predicts...   perished\n",
      "For [ 2.  1. 19.  0.  0.] the model predicts...   perished\n",
      "For [ 2.  0. 23.  0.  0.] the model predicts...   perished\n",
      "For [ 2.  0. 26.  0.  0.] the model predicts...   survived\n",
      "For [ 2.  0. 42.  0.  0.] the model predicts...   perished\n",
      "For [ 2.  0. 27.  0.  0.] the model predicts...   survived\n",
      "For [3. 0. 1. 1. 2.] the model predicts...   survived\n",
      "For [ 1.  0. 53.  1.  1.] the model predicts...   perished\n",
      "For [1. 0. 4. 0. 2.] the model predicts...   survived\n",
      "For [ 1.  1. 54.  1.  1.] the model predicts...   perished\n",
      "For [ 3.   0.  40.5  0.   0. ] the model predicts...   perished\n",
      "For [ 1.  1. 24.  3.  2.] the model predicts...   survived\n",
      "For [ 1.  1. 28.  3.  2.] the model predicts...   perished\n",
      "For [ 1.  1. 23.  3.  2.] the model predicts...   survived\n",
      "For [ 1.  0. 19.  3.  2.] the model predicts...   perished\n",
      "For [ 1.  0. 64.  1.  4.] the model predicts...   perished\n",
      "For [ 1.  1. 60.  1.  4.] the model predicts...   perished\n",
      "For [ 2.  0. 24.  2.  0.] the model predicts...   perished\n",
      "For [ 2.  0. 32.  2.  0.] the model predicts...   perished\n",
      "For [ 2.  0. 21.  2.  0.] the model predicts...   perished\n",
      "For [ 2.  1. 18.  1.  1.] the model predicts...   perished\n",
      "For [ 2.  1. 20.  2.  1.] the model predicts...   perished\n",
      "For [ 2.  0. 23.  2.  1.] the model predicts...   perished\n",
      "For [ 2.  0. 36.  0.  0.] the model predicts...   perished\n",
      "For [ 2.  1. 54.  1.  3.] the model predicts...   perished\n",
      "For [2. 0. 1. 0. 2.] the model predicts...   survived\n",
      "For [ 2.  0. 31.  1.  1.] the model predicts...   perished\n",
      "For [ 2.  1. 24.  1.  1.] the model predicts...   survived\n",
      "For [ 1.  0. 62.  0.  0.] the model predicts...   perished\n",
      "For [ 1.  1. 36.  0.  0.] the model predicts...   perished\n"
     ]
    }
   ],
   "source": [
    "predictions = predict_new_data ( X_unknown, knn_model )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
